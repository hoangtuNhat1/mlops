{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2bd82d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.14\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bcb1699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://test-bucket-mlflow-123/2', creation_time=1726197846122, experiment_id='2', last_update_time=1726197846122, lifecycle_stage='active', name='mlops-zoomcamlp', tags={}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Set the tracking URI to an SQLite database file\n",
    "mlflow.set_tracking_uri('http://ec2-54-147-138-249.compute-1.amazonaws.com:5000')\n",
    "\n",
    "# Set the experiment name\n",
    "mlflow.set_experiment(\"mlops-zoomcamlp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b135c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ed8efc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'http://ec2-54-147-138-249.compute-1.amazonaws.com:5000'\n"
     ]
    }
   ],
   "source": [
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9e6479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "        df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "    elif filename.endswith('.parquet'):\n",
    "        df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8029eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-01.parquet')\n",
    "df_val = read_dataframe('https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "951d51ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5cbfc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PU_DO'] #'PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = train_dicts\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = val_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0ffd4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PU_DO</th>\n",
       "      <th>trip_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43_151</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PU_DO  trip_distance\n",
       "0  43_151           1.01"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[categorical + numerical].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e9fb68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "429e2394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from mlflow.models.signature import infer_signature\n",
    "import mlflow.xgboost\n",
    "from hyperopt.pyll.base import scope\n",
    "from sklearn.pipeline import Pipeline\n",
    "def objective(params):\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # Log hyperparameters\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Create a pipeline with DictVectorizer and XGBoost\n",
    "        pipeline = Pipeline([\n",
    "            ('dv', DictVectorizer()),  # Step 1: Vectorize the dictionary data\n",
    "            ('xgb_model', xgb.XGBRegressor(**params))  # Step 2: Train XGBoost model\n",
    "        ])\n",
    "\n",
    "        # Prepare training data\n",
    "        train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "        X_train = train_dicts\n",
    "        val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "        X_val = val_dicts\n",
    "\n",
    "        # Fit the pipeline\n",
    "        pipeline.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on validation set\n",
    "        y_pred = pipeline.predict(X_val)\n",
    "\n",
    "        # Calculate RMSE and log the metric\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "        # Log the entire pipeline to MLflow\n",
    "        signature = infer_signature(X_val, y_pred)\n",
    "        mlflow.sklearn.log_model(pipeline, \"pipeline_model\", signature=signature)\n",
    "\n",
    "        return {'loss': rmse, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b64ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'max_depth': scope.int(hp.quniform('max_depth', 3, 10, 1)),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "    'n_estimators': scope.int(hp.quniform('n_estimators', 100, 1000, 100)),\n",
    "    'min_child_weight': hp.uniform('min_child_weight', 1, 10),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1041a603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/13 11:29:12 INFO mlflow.tracking._tracking_service.client: 🏃 View run rogue-croc-156 at: http://ec2-54-147-138-249.compute-1.amazonaws.com:5000/#/experiments/2/runs/fe42f4c806ce4fbc8dd0ca201505ee2f.\n",
      "\n",
      "2024/09/13 11:29:12 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-54-147-138-249.compute-1.amazonaws.com:5000/#/experiments/2.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:49<00:00, 169.12s/trial, best loss: 6.403343604032129]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/13 11:29:14 INFO mlflow.tracking._tracking_service.client: 🏃 View run colorful-sheep-194 at: http://ec2-54-147-138-249.compute-1.amazonaws.com:5000/#/experiments/2/runs/3d7ff8c67f1444b798ed62a955fa45db.\n",
      "2024/09/13 11:29:14 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-54-147-138-249.compute-1.amazonaws.com:5000/#/experiments/2.\n"
     ]
    }
   ],
   "source": [
    "train_data_url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet'\n",
    "val_data_url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet'\n",
    "with mlflow.start_run(): \n",
    "    # Log the developer tag\n",
    "    mlflow.set_tag(\"model\", \"xgboost\")\n",
    "    \n",
    "    # Log data source URLs as tags\n",
    "    mlflow.set_tag(\"train_data_url\", train_data_url)\n",
    "    mlflow.set_tag(\"val_data_url\", val_data_url)\n",
    "\n",
    "    # Read and log datasets\n",
    "    mlflow.log_param(\"train_data_shape\", df_train.shape)\n",
    "    mlflow.log_param(\"validation_data_shape\", df_val.shape)\n",
    "\n",
    "\n",
    "    # Sample the first few rows of the datasets and log them as artifacts\n",
    "    df_train.head(5).to_csv(\"train_sample.csv\", index=False)\n",
    "    df_val.head(5).to_csv(\"val_sample.csv\", index=False)\n",
    "    mlflow.log_artifact(\"train_sample.csv\")\n",
    "    mlflow.log_artifact(\"val_sample.csv\")\n",
    "    \n",
    "    # Tune the XGBoost model using Hyperopt\n",
    "    trials = Trials()\n",
    "    best_params = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=1, trials=trials)\n",
    "\n",
    "    # Log the best hyperparameters\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # Optionally log the full dataset or additional visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c7a0ef5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mX_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da685dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/13 13:25:04 INFO mlflow.tracking._tracking_service.client: 🏃 View run rumbling-moth-324 at: http://ec2-54-147-138-249.compute-1.amazonaws.com:5000/#/experiments/2/runs/6defa097ca3c46268bbe0e9db459903c.\n",
      "2024/09/13 13:25:04 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://ec2-54-147-138-249.compute-1.amazonaws.com:5000/#/experiments/2.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Please reshape the input data into 2-dimensional matrix.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m mlflow\u001b[38;5;241m.\u001b[39mlog_params(best_params)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Convert data to DMatrix (XGBoost data structure)\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m dtrain \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m dval \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_val, label\u001b[38;5;241m=\u001b[39my_val)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Train model with early stopping\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/pbl6/lib/python3.10/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pbl6/lib/python3.10/site-packages/xgboost/core.py:878\u001b[0m, in \u001b[0;36mDMatrix.__init__\u001b[0;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m handle, feature_names, feature_types \u001b[38;5;241m=\u001b[39m \u001b[43mdispatch_data_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnthread\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_split_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_split_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;241m=\u001b[39m handle\n",
      "File \u001b[0;32m~/anaconda3/envs/pbl6/lib/python3.10/site-packages/xgboost/data.py:1209\u001b[0m, in \u001b[0;36mdispatch_data_backend\u001b[0;34m(data, missing, threads, feature_names, feature_types, enable_categorical, data_split_mode)\u001b[0m\n\u001b[1;32m   1207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _from_uri(data, missing, feature_names, feature_types, data_split_mode)\n\u001b[1;32m   1208\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_list(data):\n\u001b[0;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_from_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_split_mode\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_tuple(data):\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _from_tuple(\n\u001b[1;32m   1214\u001b[0m         data, missing, threads, feature_names, feature_types, data_split_mode\n\u001b[1;32m   1215\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/pbl6/lib/python3.10/site-packages/xgboost/data.py:1125\u001b[0m, in \u001b[0;36m_from_list\u001b[0;34m(data, missing, n_threads, feature_names, feature_types, data_split_mode)\u001b[0m\n\u001b[1;32m   1123\u001b[0m array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data)\n\u001b[1;32m   1124\u001b[0m _check_data_shape(data)\n\u001b[0;32m-> 1125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_from_numpy_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_split_mode\u001b[49m\n\u001b[1;32m   1127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pbl6/lib/python3.10/site-packages/xgboost/data.py:252\u001b[0m, in \u001b[0;36m_from_numpy_array\u001b[0;34m(data, missing, nthread, feature_names, feature_types, data_split_mode)\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_numpy_array\u001b[39m(\n\u001b[1;32m    244\u001b[0m     data: DataType,\n\u001b[1;32m    245\u001b[0m     missing: FloatCompatible,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    249\u001b[0m     data_split_mode: DataSplitMode \u001b[38;5;241m=\u001b[39m DataSplitMode\u001b[38;5;241m.\u001b[39mROW,\n\u001b[1;32m    250\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DispatchedDataBackendReturnType:\n\u001b[1;32m    251\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialize data from a 2-D numpy matrix.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 252\u001b[0m     \u001b[43m_check_data_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m     data, _ \u001b[38;5;241m=\u001b[39m _ensure_np_dtype(data, data\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    254\u001b[0m     handle \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_void_p()\n",
      "File \u001b[0;32m~/anaconda3/envs/pbl6/lib/python3.10/site-packages/xgboost/data.py:58\u001b[0m, in \u001b[0;36m_check_data_shape\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_data_shape\u001b[39m(data: DataType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 58\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease reshape the input data into 2-dimensional matrix.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Please reshape the input data into 2-dimensional matrix."
     ]
    }
   ],
   "source": [
    "best_params = {\n",
    "    \"colsample_bytree\": 0.9447724401254488,\n",
    "    \"learning_rate\": 0.2576928125052712,\n",
    "    \"max_depth\": 10,\n",
    "    \"reg_alpha\": 0.01735745977982242,\n",
    "    \"reg_lambda\": 0.04766124633013455,\n",
    "    \"subsample\": 0.7076825876246899\n",
    "}\n",
    "\n",
    "with mlflow.start_run(nested=True):\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_params(best_params)\n",
    "    \n",
    "    # Convert data to DMatrix (XGBoost data structure)\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(X_val, label=y_val)\n",
    "    \n",
    "    # Train model with early stopping\n",
    "    model = xgb.train(best_params, \n",
    "                      dtrain, \n",
    "                      evals=[(dval, 'validation')], \n",
    "                      early_stopping_rounds=10,\n",
    "                      num_boost_round=50, \n",
    "                      verbose_eval=False)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred = model.predict(dval)\n",
    "\n",
    "    # Calculate RMSE and log the metric\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    \n",
    "    # Log model signature and input example\n",
    "    signature = infer_signature(X_val, y_pred)\n",
    "    \n",
    "    # Provide an input example (1 sample) for model logging\n",
    "    input_example = X_val[0:1]  # Adjust if needed for correct format\n",
    "    mlflow.xgboost.log_model(model, \"xgboost_model\", signature=signature, input_example=input_example)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7ed9bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 16:36:18 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'numpy.ndarray' object has no attribute 'toarray'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged LinearRegression with RMSE: 7.758715203341164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 16:36:32 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'numpy.ndarray' object has no attribute 'toarray'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged RandomForest with RMSE: 6.913010836412057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 16:59:31 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'numpy.ndarray' object has no attribute 'toarray'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged GradientBoosting with RMSE: 6.742303328497425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Start MLflow run\n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"RandomForest\": RandomForestRegressor(),\n",
    "    \"GradientBoosting\": GradientBoostingRegressor(),\n",
    "}\n",
    "for model_name, model in models.items():\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        # Enable autologging\n",
    "        mlflow.sklearn.autolog()\n",
    "\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on validation set\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        # Calculate and log RMSE\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"Logged {model_name} with RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bf6f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Create the 'models' directory if it doesn't exist\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "# Save the model to a file\n",
    "with open('models/lin_reg.bin', 'wb') as f_out:\n",
    "    pickle.dump((dv, lr), f_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "eec6b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the model from the file\n",
    "with open('models/lin_reg.bin', 'rb') as f_in:\n",
    "    dv, lr = pickle.load(f_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "47b0eb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_val[0])\n",
    "\n",
    "# root_mean_squared_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5e5ecb98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.99325864])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
