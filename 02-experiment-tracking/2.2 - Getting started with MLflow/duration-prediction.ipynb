{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2bd82d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.14\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bcb1699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 10:11:26 INFO mlflow.store.db.utils: Creating initial MLflow database tables...\n",
      "2024/09/06 10:11:27 INFO mlflow.store.db.utils: Updating database tables\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "INFO  [alembic.runtime.migration] Running upgrade  -> 451aebb31d03, add metric step\n",
      "INFO  [alembic.runtime.migration] Running upgrade 451aebb31d03 -> 90e64c465722, migrate user column to tags\n",
      "INFO  [alembic.runtime.migration] Running upgrade 90e64c465722 -> 181f10493468, allow nulls for metric values\n",
      "INFO  [alembic.runtime.migration] Running upgrade 181f10493468 -> df50e92ffc5e, Add Experiment Tags Table\n",
      "INFO  [alembic.runtime.migration] Running upgrade df50e92ffc5e -> 7ac759974ad8, Update run tags with larger limit\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7ac759974ad8 -> 89d4b8295536, create latest metrics table\n",
      "INFO  [89d4b8295536_create_latest_metrics_table_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 89d4b8295536 -> 2b4d017a5e9b, add model registry tables to db\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Adding registered_models and model_versions tables to database.\n",
      "INFO  [2b4d017a5e9b_add_model_registry_tables_to_db_py] Migration complete!\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2b4d017a5e9b -> cfd24bdc0731, Update run status constraint with killed\n",
      "INFO  [alembic.runtime.migration] Running upgrade cfd24bdc0731 -> 0a8213491aaa, drop_duplicate_killed_constraint\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0a8213491aaa -> 728d730b5ebd, add registered model tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 728d730b5ebd -> 27a6a02d2cf1, add model version tags table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 27a6a02d2cf1 -> 84291f40a231, add run_link to model_version\n",
      "INFO  [alembic.runtime.migration] Running upgrade 84291f40a231 -> a8c4a736bde6, allow nulls for run_id\n",
      "INFO  [alembic.runtime.migration] Running upgrade a8c4a736bde6 -> 39d1c3be5f05, add_is_nan_constraint_for_metrics_tables_if_necessary\n",
      "INFO  [alembic.runtime.migration] Running upgrade 39d1c3be5f05 -> c48cb773bb87, reset_default_value_for_is_nan_in_metrics_table_for_mysql\n",
      "INFO  [alembic.runtime.migration] Running upgrade c48cb773bb87 -> bd07f7e963c5, create index on run_uuid\n",
      "INFO  [alembic.runtime.migration] Running upgrade bd07f7e963c5 -> 0c779009ac13, add deleted_time field to runs table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 0c779009ac13 -> cc1f77228345, change param value length to 500\n",
      "INFO  [alembic.runtime.migration] Running upgrade cc1f77228345 -> 97727af70f4d, Add creation_time and last_update_time to experiments table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 97727af70f4d -> 3500859a5d39, Add Model Aliases table\n",
      "INFO  [alembic.runtime.migration] Running upgrade 3500859a5d39 -> 7f2a7d5fae7d, add datasets inputs input_tags tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 7f2a7d5fae7d -> 2d6e25af4d3e, increase max param val length from 500 to 8000\n",
      "INFO  [alembic.runtime.migration] Running upgrade 2d6e25af4d3e -> acf3f17fdcc7, add storage location field to model versions\n",
      "INFO  [alembic.runtime.migration] Running upgrade acf3f17fdcc7 -> 867495a8f9d4, add trace tables\n",
      "INFO  [alembic.runtime.migration] Running upgrade 867495a8f9d4 -> 5b0e9adcef9c, add cascade deletion to trace tables foreign keys\n",
      "INFO  [alembic.runtime.migration] Running upgrade 5b0e9adcef9c -> 4465047574b1, increase max dataset schema size\n",
      "INFO  [alembic.runtime.migration] Context impl SQLiteImpl.\n",
      "INFO  [alembic.runtime.migration] Will assume non-transactional DDL.\n",
      "2024/09/06 10:11:37 INFO mlflow.tracking.fluent: Experiment with name 'mlops-zoomcamlp' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='/media/nhutpham/Work1/MLOpsZoomcap/mlops-zoomcamp/02-experiment-tracking/mlruns/1', creation_time=1725592297969, experiment_id='1', last_update_time=1725592297969, lifecycle_stage='active', name='mlops-zoomcamlp', tags={}>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Set the tracking URI to an SQLite database file\n",
    "mlflow.set_tracking_uri(\"sqlite:///mlflow.db\")\n",
    "\n",
    "# Set the experiment name\n",
    "mlflow.set_experiment(\"mlops-zoomcamlp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41062d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c984c564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4add538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b135c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.metrics import root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9e6479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(filename)\n",
    "\n",
    "        df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "        df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "    elif filename.endswith('.parquet'):\n",
    "        df = pd.read_parquet(filename)\n",
    "\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8029eba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_dataframe('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet')\n",
    "df_val = read_dataframe('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6f2f0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1343254, 1340859)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91fccbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_std = df_train['duration'].std() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cda2dd7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(8.86526930029462)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c52b305c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Total number of records before removing outliers\n",
    "# initial_count = len(df_train)\n",
    "\n",
    "# # Remove outliers by keeping only rows where 'duration' is between 1 and 60 minutes\n",
    "# df_train_filtered = df_train[(df_train['duration'] >= 1) & (df_train['duration'] <= 60)]\n",
    "\n",
    "# # Total number of records after removing outliers\n",
    "# final_count = len(df_train_filtered)\n",
    "\n",
    "# # Calculate the fraction of records left\n",
    "# fraction_left = final_count / initial_count\n",
    "\n",
    "# print(f\"Fraction of records left: {fraction_left:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33ed415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cast the IDs to strings\n",
    "# df_train['PULocationID'] = df_train['PULocationID'].astype(str)\n",
    "# df_train['DOLocationID'] = df_train['DOLocationID'].astype(str)\n",
    "\n",
    "# # Turn the DataFrame into a list of dictionaries using only 'PULocationID' and 'DOLocationID'\n",
    "# data_dicts = df_train[['PULocationID', 'DOLocationID']].to_dict(orient='records')\n",
    "\n",
    "# # Fit a DictVectorizer\n",
    "# vectorizer = DictVectorizer(sparse=False)\n",
    "# feature_matrix = vectorizer.fit_transform(data_dicts)\n",
    "\n",
    "# # Get the dimensionality of the matrix\n",
    "# num_columns = feature_matrix.shape[1]\n",
    "\n",
    "# print(f\"The dimensionality of the matrix is: {num_columns} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63ba5abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
       "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
       "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
       "       'total_amount', 'congestion_surcharge', 'airport_fee', 'duration'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "951d51ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['PU_DO'] = df_train['PULocationID'] + '_' + df_train['DOLocationID']\n",
    "df_val['PU_DO'] = df_val['PULocationID'] + '_' + df_val['DOLocationID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5cbfc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['PU_DO'] #'PULocationID', 'DOLocationID']\n",
    "numerical = ['trip_distance']\n",
    "\n",
    "dv = DictVectorizer()\n",
    "\n",
    "train_dicts = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e9fb68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "429e2394",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/06 11:27:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "train_data_url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet'\n",
    "val_data_url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet'\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run(): \n",
    "    # Log the developer tag\n",
    "    mlflow.set_tag(\"developer\", \"nhutpham\")\n",
    "    \n",
    "    # Log parameters\n",
    "    alpha = 0.01\n",
    "    mlflow.log_param(\"alpha\", alpha)\n",
    "\n",
    "    # Log data source URLs as tags\n",
    "    mlflow.set_tag(\"train_data_url\", train_data_url)\n",
    "    mlflow.set_tag(\"val_data_url\", val_data_url)\n",
    "\n",
    "    # Read and log datasets\n",
    "    df_train = read_dataframe(train_data_url)\n",
    "    df_val = read_dataframe(val_data_url)\n",
    "\n",
    "    mlflow.log_param(\"train_data_shape\", df_train.shape)\n",
    "    mlflow.log_param(\"validation_data_shape\", df_val.shape)\n",
    "\n",
    "    # Sample the first few rows of the datasets and log them as artifacts\n",
    "    df_train.head(5).to_csv(\"train_sample.csv\", index=False)\n",
    "    df_val.head(5).to_csv(\"val_sample.csv\", index=False)\n",
    "    mlflow.log_artifact(\"train_sample.csv\")\n",
    "    mlflow.log_artifact(\"val_sample.csv\")\n",
    "    \n",
    "    # Model training\n",
    "    lr = Ridge(alpha=alpha)\n",
    "\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and log the predictions\n",
    "    y_pred = lr.predict(X_val)\n",
    "    np.savetxt(\"predictions.csv\", y_pred, delimiter=\",\")\n",
    "    mlflow.log_artifact(\"predictions.csv\")\n",
    "\n",
    "    # Log performance metrics\n",
    "    rmse = root_mean_squared_error(y_val, y_pred)\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "\n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(lr, \"ridge_model\")\n",
    "\n",
    "    # Optionally log the full dataset or additional visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22bf6f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "# Create the 'models' directory if it doesn't exist\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "# Save the model to a file\n",
    "with open('models/lin_reg.bin', 'wb') as f_out:\n",
    "    pickle.dump((dv, lr), f_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eec6b020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the model from the file\n",
    "with open('models/lin_reg.bin', 'rb') as f_in:\n",
    "    dv, lr = pickle.load(f_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47b0eb9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(4.992299116111529)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = lr.predict(X_val)\n",
    "\n",
    "root_mean_squared_error(y_val, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
